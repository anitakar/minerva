{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "Implement probability calibration transformer.\n",
    "\n",
    "As was explained in the blog https://blog.deepsense.ai/deep-learning-right-whale-recognition-kaggle/\n",
    "probability calibration was an important step that improved the results considerably.\n",
    "\n",
    "The idea is simple. You should take the output `y_pred` from the network and raise it to the power of `1.1 - 1.6`\n",
    "\n",
    "You will learn how to do it cleanly with a BaseTransformer object that is used heavily in this project.\n",
    "\n",
    "It was used to improve the log loss on classification so use `-s classification` in the execution command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Solution\n",
    "Your solution function should be called solution. In this case we leave it for consistency but you don't need to do anything with it. \n",
    "\n",
    "CONFIG is a dictionary with all parameters that you want to pass to your solution function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG={},\n",
    "\n",
    "def solution():\n",
    "    \"\"\"\n",
    "    Create your ProbabilityCalibration implementation and\n",
    "    output an instance of that class.\n",
    "    \"\"\"\n",
    "    class DatasetLocalizer(Dataset):\n",
    "        def __init__(self, X, y, img_dirpath, augmentation, target_size, bins_nr):\n",
    "            super().__init__()\n",
    "            self.img_dirpath = img_dirpath\n",
    "            self.X = X.reset_index(drop=True)\n",
    "            \n",
    "            self.target_size = target_size\n",
    "            self.bins_nr = bins_nr\n",
    "            self.augmentation = augmentation\n",
    "            self.preprocessing_function = localizer_preprocessing\n",
    "            self.normalization_function = normalization\n",
    "\n",
    "        def load_image(self, img_name):\n",
    "            \"\"\"\n",
    "            Read image from disk to numpy array\n",
    "            \"\"\"\n",
    "            return NotImplementedError\n",
    "\n",
    "        def __len__(self):\n",
    "            \"\"\"\n",
    "            Determine the length of the dataset\n",
    "            \"\"\"\n",
    "            return length\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            \"\"\"\n",
    "            \n",
    "            \"\"\"\n",
    "            return Xi_tensor, yi_tensors\n",
    "\n",
    "    return DatasetLocalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetBasic(Dataset):\n",
    "    def __init__(self, X, y, img_dirpath, augmentation, target_size, bins_nr):\n",
    "        super().__init__()\n",
    "        self.img_dirpath = img_dirpath\n",
    "        self.X = X.reset_index(drop=True)\n",
    "        if y is not None:\n",
    "            self.y = y.reset_index(drop=True)\n",
    "        else:\n",
    "            \"\"\"\n",
    "            Wouldn't work with kaggle submission Fix it\n",
    "            \"\"\"\n",
    "            raise NotImplementedError('Not working with y being None')\n",
    "        self.target_size = target_size\n",
    "        self.bins_nr = bins_nr\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing_function = None\n",
    "        self.normalization_function = None\n",
    "\n",
    "    def load_image(self, img_name):\n",
    "        img_filepath = os.path.join(self.img_dirpath, img_name)\n",
    "        return Image.open(img_filepath, 'r')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.X['Image'].iloc[index]\n",
    "        yi = self.y.iloc[index]\n",
    "\n",
    "        Xi_img = self.load_image(img_name)\n",
    "        Xi = np.asarray(Xi_img)\n",
    "\n",
    "        Xi, yi = self.preprocessing_function(Xi, yi, self.augmentation, self.target_size, self.bins_nr)\n",
    "        Xi = self.normalization_function(Xi)\n",
    "\n",
    "        Xi_tensor = torch.from_numpy(Xi).permute(2, 0, 1).type(torch.FloatTensor)\n",
    "        yi_tensors = torch.from_numpy(yi).type(torch.LongTensor)\n",
    "        return Xi_tensor, yi_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localizer_preprocessing(img, target, augmentation, target_size, bins_nr):\n",
    "    height, width = target_size\n",
    "\n",
    "    scale = iaa.Scale({\"height\": height, \"width\": width}).to_deterministic()\n",
    "    augmenter = iaa.Sequential([iaa.Affine(rotate=(-10, 10),\n",
    "                                           scale=(1 / 1.2, 1.2)),\n",
    "                                #  KirzhevskyColorPerturbation\n",
    "                                ]).to_deterministic()\n",
    "\n",
    "    if augmentation:\n",
    "        transformations = [augmenter, scale]\n",
    "    else:\n",
    "        transformations = [scale]\n",
    "    transformer = iaa.Sequential(transformations).to_deterministic()\n",
    "\n",
    "    aug_X = transformer.augment_image(img)\n",
    "\n",
    "    keypoints = ia.KeypointsOnImage([\n",
    "        ia.Keypoint(x=int(target.bbox1_x), y=int(target.bbox1_y)),\n",
    "        ia.Keypoint(x=int(target.bbox2_x), y=int(target.bbox2_y))],\n",
    "        shape=img.shape)\n",
    "    aug_points = transformer.augment_keypoints([keypoints])\n",
    "    aug_points_formatted = np.reshape(aug_points[0].get_coords_array(), -1).astype(np.float)\n",
    "    aug_points_binned = bin_quantizer(aug_points_formatted, (height, width), bins_nr)\n",
    "\n",
    "    return aug_X, aug_points_binned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "64px",
    "width": "255px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
